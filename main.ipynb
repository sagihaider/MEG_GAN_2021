{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPt53432wNd96iALffijmMj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagihaider/MEG_GAN_2021/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRfLqYGRBwLx"
      },
      "source": [
        "import numpy as np\n",
        "from keras.layers import Input, Dense, Activation, BatchNormalization, PReLU, Dropout\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_optimizer():\n",
        "    #return SGD(lr =  0.01, momentum = 0.1)\n",
        "    return Adam(lr = 0.0003)\n",
        "\n",
        "def build_models(n_neurons):\n",
        "    \"\"\"Creates three different models, one used for source only training, two used for domain adaptation\"\"\"\n",
        "    inputs = Input(shape=(12,)) # We have 20 variables in the EEG data from FBCSP\n",
        "    x4 = Dense(32, activation='linear', kernel_regularizer = \"l2\")(inputs)\n",
        "    x4 = BatchNormalization()(x4)\n",
        "    x4 = Activation(\"tanh\")(x4)  \n",
        "    x4 = Dropout(0.5)(x4)\n",
        "    \n",
        "    x4 = Dense(2, activation='linear', kernel_regularizer = \"l2\")(x4)\n",
        "    x4 = BatchNormalization()(x4)\n",
        "    x4 = Activation(\"tanh\")(x4)  \n",
        "\n",
        "    source_classifier = Dense(2, activation='softmax', name=\"mo\",  kernel_regularizer = \"l2\")(x4)  \n",
        "    \n",
        "    domain_classifier = Dense(32, activation='linear', name=\"do4\", kernel_regularizer = \"l2\", use_bias = False)(x4)\n",
        "    domain_classifier = BatchNormalization(name=\"do5\")(domain_classifier)\n",
        "    domain_classifier = Activation(\"elu\", name=\"do6\")(domain_classifier)\n",
        "    #domain_classifier = Dropout(0.25)(domain_classifier)\n",
        "\n",
        "    domain_classifier = Dense(2, activation='softmax',  kernel_regularizer = \"l2\", name=\"do\")(domain_classifier)\n",
        "\n",
        "    comb_model = Model(inputs=inputs, outputs=[source_classifier, domain_classifier])\n",
        "    comb_model.compile(optimizer=get_optimizer(),\n",
        "              loss={'mo': 'categorical_crossentropy', 'do': 'categorical_crossentropy'},\n",
        "              loss_weights={'mo': 1, 'do': 1}, metrics=['accuracy'], )\n",
        "\n",
        "    source_classification_model = Model(inputs=inputs, outputs=[source_classifier])\n",
        "    source_classification_model.compile(optimizer=get_optimizer(),\n",
        "              loss={'mo': 'categorical_crossentropy'}, metrics=['accuracy'], )\n",
        "\n",
        "\n",
        "    domain_classification_model = Model(inputs=inputs, outputs=[domain_classifier])\n",
        "    domain_classification_model.compile(optimizer=get_optimizer(),\n",
        "                  loss={'do': 'categorical_crossentropy'}, metrics=['accuracy'])\n",
        "    \n",
        "    \n",
        "    embeddings_model = Model(inputs=inputs, outputs=[x4])\n",
        "    embeddings_model.compile(optimizer=get_optimizer(),loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "                        \n",
        "    comb_model.summary()      \n",
        "    source_classification_model.summary()          \n",
        "    domain_classification_model.summary()       \n",
        "    embeddings_model.summary()\n",
        "    return comb_model, source_classification_model, domain_classification_model, embeddings_model\n",
        "\n",
        "def batch_generator(data, batch_size):\n",
        "    \"\"\"Generate batches of data.\n",
        "\n",
        "    Given a list of numpy data, it iterates over the list and returns batches of the same size\n",
        "    This\n",
        "    \"\"\"\n",
        "    all_examples_indices = len(data[0])\n",
        "    while True:\n",
        "        mini_batch_indices = np.random.choice(all_examples_indices, size=batch_size, replace=False)\n",
        "        tbr = [k[mini_batch_indices] for k in data]\n",
        "        yield tbr\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "#SAMPLING_ITERATIONS = 3000\n",
        "\n",
        "def train(Xs, ys, Xt, yt,  enable_dann = True, n_iterations = 1000):\n",
        "    \n",
        "    batch_size = len(Xs)\n",
        "    \n",
        "    model, source_classification_model, domain_classification_model, embeddings_model = build_models(2) # Number of neurons for shared layer\n",
        "\n",
        "    y_class_dummy = np.ones((len(Xt), 2))\n",
        "    y_adversarial_1 = to_categorical(np.array(([1] * batch_size + [0] * batch_size)))\n",
        "    \n",
        "    sample_weights_class = np.array(([1] * batch_size + [0] * batch_size))\n",
        "    sample_weights_adversarial = np.ones((batch_size * 2,))\n",
        "\n",
        "    S_batches = batch_generator([Xs, to_categorical(ys)], batch_size)\n",
        "    T_batches = batch_generator([Xt, np.zeros(shape = (len(Xt),2))], batch_size)\n",
        "    \n",
        "    for i in range(n_iterations):\n",
        "        # # print(y_class_dummy.shape, ys.shape)\n",
        "        y_adversarial_2 = to_categorical(np.array(([0] * batch_size + [1] * batch_size)))\n",
        "\n",
        "        X0, y0 = next(S_batches)\n",
        "        X1, y1 = next(T_batches)\n",
        "\n",
        "\n",
        "        X_adv = np.concatenate([X0, X1])\n",
        "        y_class = np.concatenate([y0, np.zeros_like(y0)])\n",
        "\n",
        "        adv_weights = []\n",
        "        for layer in model.layers:\n",
        "            if (layer.name.startswith(\"do\")):\n",
        "                adv_weights.append(layer.get_weights())\n",
        "\n",
        "        if(enable_dann):\n",
        "            # note - even though we save and append weights, the batchnorms moving means and variances\n",
        "            # are not saved throught this mechanism \n",
        "            stats = model.train_on_batch(X_adv, [y_class, y_adversarial_1],\n",
        "                                     sample_weight=[sample_weights_class, sample_weights_adversarial])\n",
        "            \n",
        "            k = 0\n",
        "            for layer in model.layers:\n",
        "                if (layer.name.startswith(\"do\")):\n",
        "                    layer.set_weights(adv_weights[k])\n",
        "                    k += 1\n",
        "\n",
        "            class_weights = []\n",
        "            \n",
        "        \n",
        "            for layer in model.layers:\n",
        "                if (not layer.name.startswith(\"do\")):\n",
        "                    class_weights.append(layer.get_weights())\n",
        "            \n",
        "            stats2 = domain_classification_model.train_on_batch(X_adv, [y_adversarial_2])\n",
        "\n",
        "            k = 0\n",
        "            for layer in model.layers:\n",
        "                if (not layer.name.startswith(\"do\")):\n",
        "                    layer.set_weights(class_weights[k])\n",
        "                    k += 1\n",
        "\n",
        "        else:\n",
        "            source_classification_model.train_on_batch(X0,y0)\n",
        "            \n",
        "       \n",
        "        # if ((i + 1) % 1000 == 0):\n",
        "        #     # print(i, stats)\n",
        "        #     y_test_hat_t = source_classification_model.predict(Xt).argmax(1)\n",
        "        #     y_test_hat_s = source_classification_model.predict(Xs).argmax(1)\n",
        "        #     print(\"Iteration %d, source accuracy =  %.3f, target accuracy = %.3f\"%(i, accuracy_score(ys, y_test_hat_s), accuracy_score(yt, y_test_hat_t)))\n",
        "        #\n",
        "\n",
        "    y_test_hat_t = source_classification_model.predict(Xt).argmax(1)\n",
        "    y_test_hat_s = source_classification_model.predict(Xs).argmax(1)\n",
        "    tr_acc=accuracy_score(ys, y_test_hat_s)\n",
        "    ts_acc=accuracy_score(yt, y_test_hat_t)\n",
        "    #print(\"Training Acc at 1500 itr: %.3f\"%(tr_acc))\n",
        "\n",
        "            \n",
        "    return embeddings_model, source_classification_model, tr_acc, ts_acc\n",
        "\n",
        "\n",
        "\n",
        "def bootstrap_train(Xs, ys, Xt, yt, enable_dann,  n_iterations = 100, n_bootstrap_iterations = 50):\n",
        "\n",
        "    y_test_hat_t_b = []\n",
        "    y_test_hat_s_b = []\n",
        "\n",
        "    for j in range(n_bootstrap_iterations):\n",
        "        all_examples_indices = len(Xs)\n",
        "        mini_batch_indices = np.random.choice(\n",
        "            all_examples_indices,\n",
        "            size=all_examples_indices,\n",
        "            replace=True\n",
        "        )\n",
        "\n",
        "        embs, model,  tr_acc, ts_acc = train(Xs[mini_batch_indices], ys[mini_batch_indices], Xt, yt, enable_dann=enable_dann, n_iterations=n_iterations)\n",
        "        print(j, \"tr_acc\", tr_acc, \"tr_acc\", ts_acc)\n",
        "        y_test_hat_t = model.predict(Xt)\n",
        "        y_test_hat_s = model.predict(Xs)\n",
        "        y_test_hat_t_b.append(y_test_hat_t)\n",
        "        y_test_hat_s_b.append(y_test_hat_s)\n",
        "\n",
        "    y_test_hat_t_b = np.array(y_test_hat_t_b)\n",
        "    y_test_hat_s_b = np.array(y_test_hat_s_b)\n",
        "\n",
        "    print(y_test_hat_t_b.shape)\n",
        "\n",
        "    tr_acc = accuracy_score(ys, y_test_hat_s_b.mean(axis = 0).argmax(1))\n",
        "    ts_acc = accuracy_score(yt, y_test_hat_t_b.mean(axis = 0).argmax(1))\n",
        "\n",
        "    return embs, model, tr_acc, ts_acc\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9ay142f2mfH"
      },
      "source": [
        "import scipy.io as spio\n",
        "from numpy import zeros\n",
        "\n",
        "cols = 2\n",
        "rows = 2\n",
        "results = zeros([rows, cols])\n",
        "results_dann = zeros([rows, cols])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-TSegYmn343i",
        "outputId": "8cbba955-baaf-4f47-93cb-2fdb80c47d4a"
      },
      "source": [
        "for x in (range(1, 2)):\n",
        "    fName = '/content/P00'+ str(x) + 'ClassComb_1_2_Features.mat'  # Load Data\n",
        "    print(fName)\n",
        "    mat = spio.loadmat(fName)\n",
        "    Xs = mat['features_tr']\n",
        "    Xs1 = Xs[0,0]\n",
        "    Xs2 = Xs[0,1]\n",
        "    Xs = np.concatenate((Xs1, Xs2), axis=1)\n",
        "    ys = mat['Y_tr']\n",
        "    yt = mat['Y_ts']\n",
        "    Xt = mat['features_ts']\n",
        "    Xt1 = Xt[0,0]\n",
        "    Xt2 = Xt[0,1]\n",
        "    Xt = np.concatenate((Xt1, Xt2), axis=1)\n",
        "\n",
        "    embs, source, tr_acc, ts_acc = bootstrap_train(Xs, ys, Xt, yt, enable_dann = False, n_iterations = 2000)\n",
        "    print(tr_acc, ts_acc)\n",
        "    results[x-1,0]=tr_acc\n",
        "    results[x-1,1]=ts_acc\n",
        "    \n",
        "    # Train a Learning Model with Domain Adaptation\n",
        "    embs, tr_acc, ts_acc = bootstrap_train(Xs, ys, Xt, yt, enable_dann = True, n_iterations = 15000)\n",
        "    results_dann[x-1,0]=tr_acc\n",
        "    results_dann[x-1,1]=ts_acc\n",
        "\n",
        "print(results)\n",
        "print(results_dann)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/P001ClassComb_1_2_Features.mat\n",
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 12)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 32)           416         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32)           128         dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32)           0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32)           0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 2)            66          dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 2)            8           dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 2)            0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "do4 (Dense)                     (None, 32)           64          activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "do5 (BatchNormalization)        (None, 32)           128         do4[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "do6 (Activation)                (None, 32)           0           do5[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "mo (Dense)                      (None, 2)            6           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "do (Dense)                      (None, 2)            66          do6[0][0]                        \n",
            "==================================================================================================\n",
            "Total params: 882\n",
            "Trainable params: 750\n",
            "Non-trainable params: 132\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 12)]              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 32)                416       \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 2)                 66        \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 2)                 8         \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "mo (Dense)                   (None, 2)                 6         \n",
            "=================================================================\n",
            "Total params: 624\n",
            "Trainable params: 556\n",
            "Non-trainable params: 68\n",
            "_________________________________________________________________\n",
            "Model: \"model_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 12)]              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 32)                416       \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 2)                 66        \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 2)                 8         \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "do4 (Dense)                  (None, 32)                64        \n",
            "_________________________________________________________________\n",
            "do5 (BatchNormalization)     (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "do6 (Activation)             (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "do (Dense)                   (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 876\n",
            "Trainable params: 744\n",
            "Non-trainable params: 132\n",
            "_________________________________________________________________\n",
            "Model: \"model_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 12)]              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 32)                416       \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 2)                 66        \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 2)                 8         \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 618\n",
            "Trainable params: 550\n",
            "Non-trainable params: 68\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-8dc36cf18732>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0membs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_dann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtr_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-c39908baae24>\u001b[0m in \u001b[0;36mbootstrap_train\u001b[0;34m(Xs, ys, Xt, yt, enable_dann, n_iterations, n_bootstrap_iterations)\u001b[0m\n\u001b[1;32m    171\u001b[0m         )\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0membs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtr_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmini_batch_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmini_batch_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_dann\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menable_dann\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tr_acc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tr_acc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0my_test_hat_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-c39908baae24>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(Xs, ys, Xt, yt, enable_dann, n_iterations)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0msource_classification_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1725\u001b[0m                                                     class_weight)\n\u001b[1;32m   1726\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:756 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:1537 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4833 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (100, 3) and (100, 2) are incompatible\n"
          ]
        }
      ]
    }
  ]
}